{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f307d401",
   "metadata": {},
   "source": [
    "# Best Trajectory Classification Model\n",
    "This notebook implements the best performing model for trajectory classification, which combines:\n",
    "1.  **Aggregated Scalar Features**: Min, max, mean, std of position and velocity.\n",
    "2.  **Physics-based Features**: Coefficients of parabolic fits ($c_2, c_1, c_0$) and residuals (deviation).\n",
    "3.  **Contextual Features**: Start location clustering and density.\n",
    "\n",
    "The model used is a **Random Forest Classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b869b929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danny\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Adding kinematic features...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "# Load Data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Preprocessing: Time and Sort\n",
    "for df in [train_df, test_df]:\n",
    "    df['time_stamp'] = pd.to_datetime(df['time_stamp'], format='mixed')\n",
    "    df['total_seconds'] = df['time_stamp'].astype('int64')\n",
    "    \n",
    "train_df = train_df.sort_values(['traj_ind', 'total_seconds'])\n",
    "test_df = test_df.sort_values(['traj_ind', 'total_seconds'])\n",
    "\n",
    "# Calculate Velocity and Speed\n",
    "def add_kinematics(df):\n",
    "    dt = df.groupby('traj_ind')['time_stamp'].diff().dt.total_seconds()\n",
    "    dx = df.groupby('traj_ind')['x'].diff()\n",
    "    dy = df.groupby('traj_ind')['y'].diff()\n",
    "    dz = df.groupby('traj_ind')['z'].diff()\n",
    "    \n",
    "    df['v_x'] = dx / dt\n",
    "    df['v_y'] = dy / dt\n",
    "    df['v_z'] = dz / dt\n",
    "    df['speed'] = (df['v_x']**2 + df['v_y']**2 + df['v_z']**2)**0.5\n",
    "    \n",
    "    # Step distance\n",
    "    df['step_dist'] = (dx**2 + dy**2 + dz**2)**0.5\n",
    "    return df\n",
    "\n",
    "print(\"Adding kinematic features...\")\n",
    "train_df = add_kinematics(train_df)\n",
    "test_df = add_kinematics(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab8a9464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Functions\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def extract_trajectory_features(df):\n",
    "    \"\"\"Extracts scalar aggregated features.\"\"\"\n",
    "    print(\"Extracting scalar features...\")\n",
    "    grp = df.groupby('traj_ind')\n",
    "    \n",
    "    aggs = grp.agg({\n",
    "        'x': ['first', 'last', 'min', 'max', 'mean', 'std'],\n",
    "        'y': ['first', 'last', 'min', 'max', 'mean', 'std'],\n",
    "        'z': ['first', 'last', 'min', 'max', 'mean', 'std'],\n",
    "        'total_seconds': ['first', 'last', 'count'],\n",
    "        'speed': ['first', 'mean', 'max', 'std'], # Added first (initial_speed)\n",
    "        'v_x': [ 'mean', 'std'], # Added first (launch velocity x)\n",
    "        'v_y': ['mean', 'std'], # Added first (launch velocity y)\n",
    "        'v_z': [ 'mean', 'std'], # Added first (launch velocity z)\n",
    "        'step_dist': ['sum']\n",
    "    })\n",
    "    \n",
    "    aggs.columns = ['_'.join(col).strip() for col in aggs.columns.values]\n",
    "    \n",
    "    # Datetime features (from traj_starts_df)\n",
    "    # total_seconds is nanoseconds since epoch\n",
    "    start_dt = pd.to_datetime(aggs['total_seconds_first'])\n",
    "    aggs['year'] = start_dt.dt.year\n",
    "    aggs['month'] = start_dt.dt.month\n",
    "    aggs['day'] = start_dt.dt.day\n",
    "    aggs['hour'] = start_dt.dt.hour\n",
    "    aggs['minute'] = start_dt.dt.minute\n",
    "    aggs['second'] = start_dt.dt.second\n",
    "    \n",
    "    # Derived features\n",
    "    aggs['duration'] = aggs['total_seconds_last'] - aggs['total_seconds_first']\n",
    "    aggs['dist_start_end'] = np.sqrt(\n",
    "        (aggs['x_last'] - aggs['x_first'])**2 + \n",
    "        (aggs['y_last'] - aggs['y_first'])**2 + \n",
    "        (aggs['z_last'] - aggs['z_first'])**2\n",
    "    )\n",
    "    aggs['straightness'] = aggs['dist_start_end'] / aggs['step_dist_sum']\n",
    "    \n",
    "    aggs.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    aggs = aggs.fillna(0)\n",
    "    return aggs\n",
    "\n",
    "def extract_physics_features(df, fit_velocity=False):\n",
    "    \"\"\"Extracts parabolic fit coefficients (position) and linear fit parameters (velocity).\"\"\"\n",
    "    print(\"Extracting physics features (Position & Velocity)...\")\n",
    "    features = []\n",
    "    indices = []\n",
    "    \n",
    "    for traj_id, group in df.groupby('traj_ind'):\n",
    "        # Prepare time\n",
    "        t_ns = group['total_seconds'].values\n",
    "        t = (t_ns - t_ns[0]) / 1e9 # Seconds\n",
    "        \n",
    "        # Position data\n",
    "        x = group['x'].values\n",
    "        y = group['y'].values\n",
    "        z = group['z'].values\n",
    "        \n",
    "        # Velocity data (handle NaNs from diff)\n",
    "        vx = group['v_x'].fillna(method='bfill').fillna(0).values\n",
    "        vy = group['v_y'].fillna(method='bfill').fillna(0).values\n",
    "        vz = group['v_z'].fillna(method='bfill').fillna(0).values\n",
    "        \n",
    "        row_data = {}\n",
    "        \n",
    "        # 1. Position Parabolic Fit: p(t) = c2*t^2 + c1*t + c0\n",
    "        if len(t) < 3:\n",
    "            # Fallback for tiny trajectories\n",
    "            for axis in ['x', 'y', 'z']:\n",
    "                row_data[f'c{axis}_2'] = 0\n",
    "                row_data[f'c{axis}_1'] = 0\n",
    "                row_data[f'c{axis}_0'] = group[axis].iloc[0] if len(group) > 0 else 0\n",
    "                row_data[f'res_{axis}'] = 0\n",
    "        else:\n",
    "            try:\n",
    "                for axis, data in zip(['x', 'y', 'z'], [x, y, z]):\n",
    "                    c, res, _, _, _ = np.polyfit(t, data, 2, full=True)\n",
    "                    row_data[f'c{axis}_2'] = c[0]\n",
    "                    row_data[f'c{axis}_1'] = c[1]\n",
    "                    row_data[f'c{axis}_0'] = c[2]\n",
    "                    row_data[f'res_{axis}'] = res[0] if len(res) > 0 else 0.0\n",
    "            except:\n",
    "                 for axis in ['x', 'y', 'z']:\n",
    "                    row_data[f'c{axis}_2'] = 0\n",
    "                    row_data[f'c{axis}_1'] = 0\n",
    "                    row_data[f'c{axis}_0'] = 0\n",
    "                    row_data[f'res_{axis}'] = 0\n",
    "        \n",
    "        # 2. Velocity Linear Fit: v(t) = acc*t + v0\n",
    "        # This captures drag/drift (acc_x, acc_y) and gravity (acc_z) directly from velocity\n",
    "        if fit_velocity:\n",
    "            if len(t) < 2:\n",
    "                for axis in ['x', 'y', 'z']:\n",
    "                    row_data[f'acc_{axis}'] = 0\n",
    "                    row_data[f'v0_fit_{axis}'] = 0\n",
    "            else:\n",
    "                t_reshaped = t.reshape(-1, 1)\n",
    "                try:\n",
    "                    for axis, data in zip(['x', 'y', 'z'], [vx, vy, vz]):\n",
    "                        model = LinearRegression()\n",
    "                        model.fit(t_reshaped, data)\n",
    "                        row_data[f'acc_{axis}'] = model.coef_[0]\n",
    "                        row_data[f'v0_fit_{axis}'] = model.intercept_\n",
    "                except:\n",
    "                    for axis in ['x', 'y', 'z']:\n",
    "                        row_data[f'acc_{axis}'] = 0\n",
    "                        row_data[f'v0_fit_{axis}'] = 0\n",
    "\n",
    "            features.append(row_data)\n",
    "            indices.append(traj_id)\n",
    "        \n",
    "    return pd.DataFrame(features, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d19ee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting scalar features...\n",
      "Extracting scalar features...\n",
      "Extracting physics features (Position & Velocity)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_8616\\1922680457.py:64: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  vx = group['v_x'].fillna(method='bfill').fillna(0).values\n",
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_8616\\1922680457.py:65: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  vy = group['v_y'].fillna(method='bfill').fillna(0).values\n",
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_8616\\1922680457.py:66: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  vz = group['v_z'].fillna(method='bfill').fillna(0).values\n",
      "c:\\Users\\danny\\anaconda3\\envs\\py310\\lib\\site-packages\\numpy\\lib\\polynomial.py:668: RuntimeWarning: invalid value encountered in divide\n",
      "  lhs /= scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting physics features (Position & Velocity)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_8616\\1922680457.py:64: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  vx = group['v_x'].fillna(method='bfill').fillna(0).values\n",
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_8616\\1922680457.py:65: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  vy = group['v_y'].fillna(method='bfill').fillna(0).values\n",
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_8616\\1922680457.py:66: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  vz = group['v_z'].fillna(method='bfill').fillna(0).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contextual features...\n",
      "Combining features...\n",
      "Final Training Shape: (32741, 41)\n",
      "Final Test Shape: (8185, 41)\n"
     ]
    }
   ],
   "source": [
    "# Generate Features\n",
    "# 1. Scalar Features\n",
    "X_train_scalar = extract_trajectory_features(train_df)\n",
    "X_test_scalar = extract_trajectory_features(test_df)\n",
    "\n",
    "# 2. Physics Features\n",
    "X_train_phys = extract_physics_features(train_df)\n",
    "X_test_phys = extract_physics_features(test_df)\n",
    "\n",
    "# 3. Contextual Features (Clustering & Density)\n",
    "print(\"Generating contextual features...\")\n",
    "# all_starts = pd.concat([\n",
    "#     X_train_scalar[['x_first', 'y_first', 'z_first']],\n",
    "#     X_test_scalar[['x_first', 'y_first', 'z_first']]\n",
    "# ])\n",
    "\n",
    "# KMeans Clustering\n",
    "# kmeans = KMeans(n_clusters=10, random_state=42, n_init=10)\n",
    "# all_starts['start_cluster'] = kmeans.fit_predict(all_starts)\n",
    "\n",
    "# # Density (KDTree)\n",
    "# tree = KDTree(all_starts[['x_first', 'y_first', 'z_first']])\n",
    "# counts = tree.query_radius(all_starts[['x_first', 'y_first', 'z_first']], r=0.1, count_only=True)\n",
    "# all_starts['start_density'] = counts\n",
    "\n",
    "# Add back to scalar features\n",
    "# X_train_scalar['start_cluster'] = all_starts.loc[X_train_scalar.index, 'start_cluster']\n",
    "# X_test_scalar['start_cluster'] = all_starts.loc[X_test_scalar.index, 'start_cluster']\n",
    "# X_train_scalar['start_density'] = all_starts.loc[X_train_scalar.index, 'start_density']\n",
    "# X_test_scalar['start_density'] = all_starts.loc[X_test_scalar.index, 'start_density']\n",
    "\n",
    "# Combine All Features\n",
    "print(\"Combining features...\")\n",
    "X_train_full = pd.concat([X_train_scalar, X_train_phys], axis=1)\n",
    "X_test_full = pd.concat([X_test_scalar, X_test_phys], axis=1)\n",
    "\n",
    "# Get Labels\n",
    "y_train = train_df.groupby('traj_ind')['label'].first().loc[X_train_full.index]\n",
    "\n",
    "print(f\"Final Training Shape: {X_train_full.shape}\")\n",
    "print(f\"Final Test Shape: {X_test_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c672fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Classifier...\n",
      "\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4472\n",
      "           1       1.00      1.00      1.00      1589\n",
      "           2       0.99      0.99      0.99       488\n",
      "\n",
      "    accuracy                           1.00      6549\n",
      "   macro avg       1.00      0.99      0.99      6549\n",
      "weighted avg       1.00      1.00      1.00      6549\n",
      "\n",
      "Accuracy: 0.9977\n",
      "\n",
      "Top 20 Important Features:\n",
      "z_first                0.132730\n",
      "x_first                0.093963\n",
      "z_min                  0.090018\n",
      "z_last                 0.072678\n",
      "z_mean                 0.057086\n",
      "x_max                  0.056069\n",
      "x_min                  0.052206\n",
      "dist_start_end         0.051907\n",
      "z_max                  0.031736\n",
      "y_first                0.030893\n",
      "z_std                  0.029979\n",
      "x_mean                 0.029345\n",
      "x_last                 0.027735\n",
      "step_dist_sum          0.019188\n",
      "v_z_mean               0.018922\n",
      "y_min                  0.018412\n",
      "straightness           0.017401\n",
      "y_max                  0.016443\n",
      "total_seconds_count    0.016439\n",
      "duration               0.015358\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Model Training and Evaluation\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "\n",
    "# Split for validation\n",
    "X_train, X_val, y_train_split, y_val_split = train_test_split(X_train_full, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train_split)\n",
    "\n",
    "# Validation\n",
    "y_pred = rf_model.predict(X_val)\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val_split, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_val_split, y_pred):.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 20 Important Features:\")\n",
    "print(importances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08bcd369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining on full dataset...\n",
      "Predicting on test set...\n",
      "Submission saved to submission_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "# Final Training and Submission\n",
    "print(\"Retraining on full dataset...\")\n",
    "rf_final = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_final.fit(X_train_full, y_train)\n",
    "\n",
    "print(\"Predicting on test set...\")\n",
    "y_test_pred = rf_final.predict(X_test_full)\n",
    "\n",
    "# Create Submission\n",
    "submission = pd.DataFrame({\n",
    "    'traj_ind': X_test_full.index,\n",
    "    'label': y_test_pred\n",
    "})\n",
    "\n",
    "output_file = 'submission_best_model.csv'\n",
    "submission.to_csv(output_file, index=False)\n",
    "print(f\"Submission saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76bf629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x_first', 'x_last', 'x_min', 'x_max', 'x_mean', 'x_std', 'y_first',\n",
       "       'y_last', 'y_min', 'y_max', 'y_mean', 'y_std', 'z_first', 'z_last',\n",
       "       'z_min', 'z_max', 'z_mean', 'z_std', 'total_seconds_first',\n",
       "       'total_seconds_last', 'total_seconds_count', 'speed_first',\n",
       "       'speed_mean', 'speed_max', 'speed_std', 'v_x_mean', 'v_x_std',\n",
       "       'v_y_mean', 'v_y_std', 'v_z_mean', 'v_z_std', 'step_dist_sum', 'year',\n",
       "       'month', 'day', 'hour', 'minute', 'second', 'duration',\n",
       "       'dist_start_end', 'straightness'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6198a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebddde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
